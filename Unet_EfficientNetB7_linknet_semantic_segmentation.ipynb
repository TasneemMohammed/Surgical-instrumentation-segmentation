{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlQ7LFszYhCn"
      },
      "outputs": [],
      "source": [
        "!pip install import_ipynb\n",
        "!pip install segmentation-models\n",
        "!pip install tensorflow==2.8\n",
        "!pip install keras==2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrSuppL-YNtj"
      },
      "outputs": [],
      "source": [
        "import import_ipynb\n",
        "%run /content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/UpdatedMeanIoU.ipynb\n",
        "#import unet\n",
        "#from unet import build_unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QMu2YdPUS0X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ef6588c6-2155-484a-88bf-ca818a53a26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation Models: using `keras` framework.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tf.keras'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#from unet import build_unet\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.metrics import MeanIoU\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4MEgWIKoQB0"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_frame_list = os.listdir(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_frame/frame\")\n",
        "train_frame_list = sorted(train_frame_list)\n",
        "print(train_frame_list)\n",
        "print(len(train_frame_list))\n",
        "\n",
        "train_mask_list = os.listdir(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_mask/mask\")\n",
        "train_mask_list = sorted(train_mask_list)\n",
        "print(train_mask_list)\n",
        "print(len(train_mask_list))\n",
        "\n",
        "for frame, mask in zip(train_frame_list, train_mask_list):\n",
        "  frame = frame.split(\".\")\n",
        "  mask = mask.split(\".\")\n",
        "  if frame[0]!=mask[0]:\n",
        "    print(frame[0], mask[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUel2Mdo60hn"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "file_path = \"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_mask/mask/video_03_000009000 (1).png\"\n",
        "# Check if the file exists before attempting to delete it\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"The file {file_path} has been deleted.\")\n",
        "else:\n",
        "    print(f\"The file {file_path} does not exist.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_sO6HVqDE2c"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_frame_list = os.listdir(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/val_frame/frame\")\n",
        "val_frame_list = sorted(val_frame_list)\n",
        "print(val_frame_list)\n",
        "print(len(val_frame_list))\n",
        "\n",
        "val_mask_list = os.listdir(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/val_mask/mask\")\n",
        "val_mask_list = sorted(val_mask_list)\n",
        "print(val_mask_list)\n",
        "print(len(val_mask_list))\n",
        "\n",
        "for frame, mask in zip(val_frame_list, val_mask_list):\n",
        "  frame = frame.split(\".\")\n",
        "  mask = mask.split(\".\")\n",
        "  if frame[0]!=mask[0]:\n",
        "    print(frame[0], mask[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6YmBGrRDEC3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "file_path = \"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/val_frame/frame/video_38_12900.jpg\"\n",
        "# Check if the file exists before attempting to delete it\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"The file {file_path} has been deleted.\")\n",
        "else:\n",
        "    print(f\"The file {file_path} does not exist.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMrlJkN_KA0a"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_frame_list = os.listdir(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/test_frame/frame\")\n",
        "test_frame_list = sorted(test_frame_list)\n",
        "print(test_frame_list)\n",
        "print(len(test_frame_list))\n",
        "\n",
        "test_mask_list = os.listdir(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/test_mask/mask\")\n",
        "test_mask_list = sorted(test_mask_list)\n",
        "print(test_mask_list)\n",
        "print(len(test_mask_list))\n",
        "\n",
        "for frame, mask in zip(test_frame_list, test_mask_list):\n",
        "  frame = frame.split(\".\")\n",
        "  mask = mask.split(\".\")\n",
        "  if frame[0]!=mask[0]:\n",
        "    print(frame[0], mask[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8789ef86-7204-4d83-87ed-22517562af51",
        "id": "mi0SI53SKiGe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfile_path = \"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/test_frame/frame/video_38_12900.jpg\"\\n# Check if the file exists before attempting to delete it\\nif os.path.exists(file_path):\\n    os.remove(file_path)\\n    print(f\"The file {file_path} has been deleted.\")\\nelse:\\n    print(f\"The file {file_path} does not exist.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "file_path = \"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/test_frame/frame/video_38_12900.jpg\"\n",
        "# Check if the file exists before attempting to delete it\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"The file {file_path} has been deleted.\")\n",
        "else:\n",
        "    print(f\"The file {file_path} does not exist.\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAZ7gyeGZ-s0"
      },
      "outputs": [],
      "source": [
        "#New generator with rotation and shear where interpolation that comes with rotation and shear are thresholded in masks.\n",
        "#This gives a binary mask rather than a mask with interpolated values.\n",
        "seed=24\n",
        "batch_size= 8\n",
        "n_classes= 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sN428F1aDzk"
      },
      "outputs": [],
      "source": [
        "img_data_gen_args = dict(rescale = 1/255., #Original pixel values are 0 and 255. So rescaling to 0 to 1\n",
        "                      width_shift_range=0.3,\n",
        "                      height_shift_range=0.3,\n",
        "                      shear_range=0.5,\n",
        "                      horizontal_flip=True,\n",
        "                      vertical_flip=True,\n",
        "                      fill_mode='reflect')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gWOqltJaOTJ",
        "outputId": "a0b338a4-aa9b-4830-e85d-d4b8a0886fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 1 classes.\n",
            "Found 200 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "#If You need to resize images then add this to the flow_from_directory parameters\n",
        "#target_size=(150, 150), #Or whatever the size is for your network\n",
        "\n",
        "image_data_generator = ImageDataGenerator(**img_data_gen_args)\n",
        "image_generator = image_data_generator.flow_from_directory(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_frame/\",\n",
        "                                                           seed=seed,\n",
        "                                                           batch_size=batch_size,\n",
        "                                                           class_mode=None)  #Very important to set this otherwise it returns multiple numpy arrays\n",
        "                                                                            #thinking class mode is binary.\n",
        "\n",
        "mask_generator = image_data_generator.flow_from_directory(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_mask/\",\n",
        "                                                         seed=seed,\n",
        "                                                         batch_size=batch_size,\n",
        "                                                         color_mode = 'grayscale',   #Read masks in grayscale\n",
        "                                                         class_mode=None)\n",
        "\n",
        "\n",
        "valid_img_generator = image_data_generator.flow_from_directory(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/val_frame/\",\n",
        "                                                               seed=seed,\n",
        "                                                               batch_size=batch_size,\n",
        "                                                               class_mode=None) #Default batch size 32, if not specified here\n",
        "valid_mask_generator = image_data_generator.flow_from_directory(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/val_mask/\",\n",
        "                                                               seed=seed,\n",
        "                                                               batch_size=batch_size,\n",
        "                                                               color_mode = 'grayscale',   #Read masks in grayscale\n",
        "                                                               class_mode=None)  #Default batch size 32, if not specified here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdq-l2dziNvS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f83b6c-c670-425c-92d0-c4ac8bc5aa2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 images belonging to 1 classes.\n",
            "Found 20 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "test_img_generator = image_data_generator.flow_from_directory(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/test_frame/\",\n",
        "                                                              seed=seed,\n",
        "                                                              batch_size=32,\n",
        "                                                              class_mode=None) #Default batch size 32, if not specified here\n",
        "\n",
        "test_mask_generator = image_data_generator.flow_from_directory(\"/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/test_mask/\",\n",
        "                                                              seed=seed,\n",
        "                                                              batch_size=32,\n",
        "                                                              color_mode = 'grayscale',   #Read masks in grayscale\n",
        "                                                              class_mode=None)  #Default batch size 32, if not specified here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki7SPQQeeeN9"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "#Dice metric can be a great metric to track accuracy of semantic segmentation.\n",
        "def dice_metric(y_pred, y_true):\n",
        "    intersection = K.sum(K.sum(K.abs(y_true * y_pred), axis=-1))\n",
        "    union = K.sum(K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1))\n",
        "    # if y_pred.sum() == 0 and y_pred.sum() == 0:\n",
        "    #     return 1.0\n",
        "\n",
        "    return 2*intersection / union\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess input\n",
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "image_generator = preprocess_input(image_generator)\n",
        "mask_generator = preprocess_input(mask_generator)\n",
        "valid_img_generator = preprocess_input(valid_img_generator)\n",
        "valid_mask_generator = preprocess_input(valid_mask_generator)\n",
        "test_img_generator = preprocess_input(test_img_generator)\n",
        "test_mask_generator = preprocess_input(test_mask_generator)\n",
        "\n",
        "train_generator = zip(image_generator,mask_generator)\n",
        "val_generator = zip(valid_img_generator, valid_mask_generator)\n",
        "test_generator = zip(test_img_generator, test_mask_generator)\n",
        "\n",
        "model1 = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
        "model2 = sm.Linknet(BACKBONE, encoder_weights='imagenet')"
      ],
      "metadata": {
        "id": "7g_PSsK86OR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mIOU = UpdatedMeanIoU(num_classes=9)\n",
        "\n",
        "num_train_imgs = len(os.listdir('/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_frame/frame/'))\n",
        "num_train_mask = len(os.listdir('/content/drive/MyDrive/ColabNotebooks/Sementatic_Segmentation/dataset_small/train_mask/mask/'))\n",
        "print(num_train_imgs, num_train_mask)\n",
        "steps_per_epoch = num_train_imgs //batch_size\n",
        "print(steps_per_epoch)\n",
        "\n",
        "\n",
        "model1.compile(optimizer=Adam(lr = 1e-3), loss='categorical_crossentropy', metrics=[mIOU, dice_metric])\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1, restore_best_weights=True,)\n",
        "\n",
        "history1=model1.fit(train_generator, validation_data=val_generator, steps_per_epoch=steps_per_epoch,\n",
        "                  validation_steps=steps_per_epoch, epochs=1,  callbacks=[early_stopping],)"
      ],
      "metadata": {
        "id": "q3vIi1mVZG-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(optimizer=Adam(lr = 1e-3), loss='categorical_crossentropy', metrics=[mIOU, dice_metric])\n",
        "\n",
        "history2=model2.fit(train_generator, validation_data=val_generator, steps_per_epoch=steps_per_epoch,\n",
        "                  validation_steps=steps_per_epoch, epochs=1,  callbacks=[early_stopping],)"
      ],
      "metadata": {
        "id": "nBwWT6buh938"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = sm.Linknet(\"efficientnetb7\", encoder_weights='imagenet')\n",
        "model3.compile(optimizer=Adam(lr = 1e-3), loss='categorical_crossentropy', metrics=[mIOU, dice_metric])\n",
        "history3=model3.fit(train_generator, validation_data=val_generator, steps_per_epoch=steps_per_epoch,\n",
        "                  validation_steps=steps_per_epoch, epochs=1,  callbacks=[early_stopping],)"
      ],
      "metadata": {
        "id": "4OmUicJac426"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_img_generator[0].shape)\n",
        "num_test_imgs = len(test_img_generator[0])\n",
        "\n",
        "print(num_test_imgs)\n",
        "batch_size = 16\n",
        "\n",
        "steps_per_epoch = num_test_imgs //batch_size\n",
        "print(steps_per_epoch)\n",
        "\n",
        "_, dice_metric, mIOU = model1.evaluate(test_generator, steps=steps_per_epoch)\n",
        "print(\"Dice metric is = \", (dice_metric * 100.0), \"%\", \"mIOU is = \", (mIOU * 100.0), \"%\")\n",
        "\n",
        "_, dice_metric, mIOU = model2.evaluate(test_generator, steps=steps_per_epoch)\n",
        "print(\"Dice metric is = \", (dice_metric * 100.0), \"%\", \"mIOU is = \", (mIOU * 100.0), \"%\")\n",
        "\n",
        "\n",
        "_, dice_metric, mIOU = model3.evaluate(test_generator, steps=steps_per_epoch)\n",
        "print(\"Dice metric is = \", (dice_metric * 100.0), \"%\", \"mIOU is = \", (mIOU * 100.0), \"%\")\n",
        "\n",
        "#we can ensemble multiple models"
      ],
      "metadata": {
        "id": "voQjNjhnZgaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndMTqIp3hRqx"
      },
      "outputs": [],
      "source": [
        "#model.save('semanticSegmentation_50epochs.hdf5')\n",
        "#model = tf.keras.models.load_model(\"semanticSegmentation_50epochs.hdf5\", compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tqL1cUj2vAb-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}